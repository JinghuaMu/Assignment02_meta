---
title: "Assignment 02"
author: "Jinghua Mu u7457359"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

!(Github repository location)[https://github.com/henflower/Assignment02_meta]


## Part I: Data Processing and Analysis
### 1. Read the study raw data and clean


```{r, message = FALSE}
# install packages
library(pacman)
p_load(tidyverse, flextable, metafor, janitor, ggpmisc, patchwork)
# Install the orchaRd package 
## devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
```

```{r, message = FALSE}
#read the data of Ckark's research and conceal the index column
current_res <- read_csv("OA_activitydat_20190302_BIOL3207.csv",name_repair = "unique",show_col_types = FALSE) %>%
                     select(-1)
#show context 
head(current_res,3)
```

```{r}
# Change some variables to factor to check that the content is correct
current_res <- current_res %>% mutate(loc = as.factor(loc),species = as.factor(species),
                                         size = as.factor(size),treatment = as.factor(treatment))
summary(current_res)
#Check the distribution of NA in the dataset
current_res %>% summarise(across(everything(), ~sum(is.na(.))))
```

No spelling errors and particularly unusual values were found, but some values were missing. Because our data is species dependent only, the lack of labels `animal ID` does not affect the availability of the data. So we only removed samples that were missing activities.  

```{r}
#Check whether the number of NA values affects data availability
table(current_res[!complete.cases(current_res$activity),] %>% select(species,loc))
#Remove missing values
current_res <- current_res[complete.cases(current_res$activity),]
```


6 samples of missing activities were removed, and the distribution of missing values was approximate to the distribution of samples, which we believe does not affect the statistical results.  


### 2. Generate statistics and merge files


```{r}
# the path of metadata file to append new infomation
append_path = "ocean_meta_data.csv"
existing_res <- read_csv(append_path,show_col_types = FALSE)
# Get the amount of information we need
glimpse(existing_res)
```

In order to add the data from the clark et al. paper to the metadata file, we needed to generate the appropriate statistics [mean,sd,N] and make the variable names consistent with each other. Therefore, we modify the names of treatment groups and change the names of individual variables, and then use `summarise()` and `pivot_longer()` to generate the statistics in the appropriate format. Finally, we read in clark's metadata and use `cbind()` to merge the experimental data with the metadata, and then use `select()` to align the data and write it to the metadata file.  
  
```{r}
# Modify our treatment names to match the reference documentation
levels(current_res$treatment)[levels(current_res$treatment)=="control"] <- "ctrl"
levels(current_res$treatment)[levels(current_res$treatment)=="CO2"] <- "oa" 
# calculate mean,SD and N of activity across each species and treatment 
current_sta <- current_res %>% group_by(treatment,species) %>% summarise(mean = mean(activity),sd = sd(activity),n = n(),.groups = "drop") %>% 
       pivot_wider(names_from = treatment,names_glue = "{treatment}.{.value}",values_from = c(mean,n,sd))
```

```{r}
# the path of supplemental information about clark's research
current_info <- read_csv("clark_paper_data.csv",show_col_types = FALSE)
# using cbind() to extend supplemental information to each experimental group
append_info <- cbind(tibble(current_info),current_sta)
# colnames(append_info)
#Fix problem with the order and partial naming of columns was found
append_info <- append_info %>%rename(Species = species) %>% select(colnames(existing_res))
```

```{r}
# write_lines("",file = append_path,append = TRUE)
# write_csv(append_info, file = append_path, append = TRUE,col_names = FALSE)
rm(list = ls())
```

### 3. Generate lnRR and sampling variance


In the previous section we found a problem with data reading for metadata, some numeric variables are read in character format, and we want to check the non-numeric content of these variables and correct all the variables into suitable format.  

```{r, warning = FALSE}
# Use *janitor* to fix column names for easy selection
meta_data <- read_csv("ocean_meta_data.csv",show_col_types = FALSE) %>% janitor::clean_names()
ini_size = nrow(meta_data)
# Some numeric variables are read in chr type, cheack the non-numeric element
unique(meta_data$pub_year_if[is.na(as.numeric(meta_data$pub_year_if))])
unique(meta_data$x2017_if[is.na(as.numeric(meta_data$x2017_if))])
```

```{r}
#Correct "-" to NA by forced type conversion. Correct some variables to factor type
meta_data[meta_data == "-"] <- NA
meta_data$cue_stimulus_type[is.na(meta_data$cue_stimulus_type)] <- "None"
meta_data <- meta_data %>% mutate(pub_year_if = as.numeric(pub_year_if), x2017_if = as.numeric(x2017_if),
                        effect_type = as.factor(effect_type), climate_fish_base = as.factor(climate_fish_base),
                        env_cue_stimulus = as.factor(env_cue_stimulus), cue_stimulus_type = as.factor(cue_stimulus_type),
                        species = as.factor(species))
# Check the dataset again
summary(meta_data)
```

The mean values of both groups were found to vary greatly between experiments. We made an attempt to convert them to Log response ratio (lnRR).  

```{r}
meta_RR <- metafor::escalc(measure = "ROM", data = meta_data,m1i = oa_mean, m2i = ctrl_mean, 
      sd1i = oa_sd, sd2i = ctrl_sd,n1i = oa_n, n2i = ctrl_n,var.names = c("lnRR", "VRR"))
```

The reason for getting NA is that $lnRR = ln\frac{\bar{X_1}}{\bar{X_2}}$, which cannot be calculated when the signs of the two response variables do not agree. We believe that the reason for the inconsistency in the sign of the two variables is that: part of the experiments screened by metadata is to measure the change from particular baseline for each treatment.  

```{r}
# Most of NA has *change/rate* in behavioural_metric 
meta_RR[!complete.cases(meta_RR$lnRR),] %>% select(study,behavioural_metric, ctrl_mean,oa_mean,lnRR)
```

We further counted the keyword occurrences of the study in which the NA experiments were found. The results showed that 104 of the 109 experiments had keywords with **change** and **rate**. We believe that such experiments do not show their effect sizes correctly by response ratio ($lnRR = ln\frac{\bar{X_1}-M}{\bar{X_2}-M} \neq \frac{\bar{X_1}}{\bar{X_2}}$).   

```{r}
# get all the study id of NA values
doubtful_study <- unique(meta_RR[!complete.cases(meta_RR$lnRR),]$study)
# number of experiments matched keyword in doubtful study
num_match <- meta_data %>% filter(study %in% doubtful_study) %>% 
         filter(grepl("change|Change|rate|Rate",behavioural_metric)) %>% nrow()
# number of experiments of all study including NA value
num_in_study <- meta_data %>% filter(study %in% doubtful_study) %>% nrow()
print(paste("Num of rows matching keywords:",num_match,",Num of experiments:",num_in_study))
```

Therefore, we chose to **label** the experiments in these studies and all other experiments with the keyword **"change"** to detect the effect size bias between these and other experiments. Also, we removed those experiments where lnRR was NA.    

```{r}
# Remove NA and mark  experiment with change or in "doubtful study"
meta_RR <- meta_RR %>%  filter(!is.na(lnRR)) %>% 
         mutate(measure_change = (study %in% doubtful_study)|grepl("change|Change",behavioural_metric) )
```

We test whether the obtained lnRR and its variance VRR have a appropriate distribution and size.  

```{r fig3, fig.cap="Distribution of lnRR and VRR before sample deletion"}
# plot distribution of lnRR and VRR
meta_RR %>% select(lnRR, VRR) %>% pivot_longer(cols = lnRR:VRR, names_to = "type", values_to = "value") %>%
      ggplot(aes(x = 1,y = value)) + geom_violin() + facet_wrap(~type, scale = "free") + ggtitle("Distribution of lnRR and VRR before sample deletion") + xlab(NULL)
```

The violin plot \@ref(fig:fig3) shows that the shape of lnRR is consistent with its normally distributed nature, but the values at both ends are large, and the extreme values of the response ratio reach the level of $e^{14}$, which is unimaginable but we cannot deny its plausibility. However, the shape of the VRR is extremely anomalous, and there are individual extremely large VRRs. we consider the results of experiments with too large variance relative to the effect values to be unreliable, and we therefore choose to remove these experiments.    
To prevent bias, we used $ (sd(lnRR) > 2|lnRR|) \cap (sd(lnRR) > ln(1.5))$ as a criterion.